# S3

## Amazon S3 Overview

- S3 allows us to store objects (files) in buckets
- Buckets must have a globally unique name
- Objects must have a *key*, that is the full path of the object. For example:
    - `<my-bucket>/my-file.txt`
    - `<my-bucket>/my-folder/another-folder/my-file.txt`
- The path will be used when doing data partitioning
- The max size of an object is `5TB`
- Objects can have up to 10 tags (key/value pairs). Tags can be useful for security/lifecycle

## Amazon S3 for Machine Learning

- It is the backbone for many AWS ML services
- S3 can be used for creating **Data Lakes**
- S3 provides:
    - Infinite size, no provisioning
    - "Eleven nines" durability
    - Decoupling of storage from compute such as EC2, Athena, Redshift, etc.
- S3 objects can be of any file format

## Amazon S3 Data Partitioning

- Partitioning is a pattern fo speeding up range queries
- We can define whatever partitioning strategy we like
- Data partitioning will be handled automatically by certain tools such as AWS Glue

## Storage Classes

- Can be the following:
    - Standard - General Purpose
    - Standard - Infrequent Access (IA)
    - One Zone - Infrequent Access
    - Glacier Instant Retrieval
    - Glacier Flexible Retrieval
    - Glacier Deep Archive
    - Intelligent Tiering
- Objects can be moved between classes manually or using S3 Lifecycle Policies
- S3 Durability:
    - Represents how many times an object can be lost from S3
    - S3 buckets have high durability (11 nines) across multiple AZs
    - If we store 10 million objects with S3, we can expect on average to lose a single object once every 10_000 years
    - Durability is the same for all storage classes
- S3 Availability:
    - Measures how readily available a service is
    - S3 availability varies depending on the storage class, for example S3 standard has 99.99% availability, meaning the service is expected to not be available for at most 53 minutes per year

### Storage Classes in details:

-  Standard - General Purpose:
    - 99.99 availability
    - Can be used for frequently accessed data
    - Provides low latency and high throughput
    - Can sustain 2 concurrent facility failures (AZ failures)
    - Recommended for big data analytics, mobile and gaming applications, content distribution, etc.
- Infrequent Access:
    - Recommended for data that is less frequently accessed, but it requires rapid access when needed
    - Has lower cost than S3 Standard, but has additional cost on data retrieval
    - There are 2 types of IA storage classes:
        - Standard:
            - 99.9% availability
            - Recommended for disaster recovery and backups
        - One Zone:
            - Provides high durability in a single AZ
            - Data can be lost if the AZ suffers an outage
            - 99.5% availability
            - Recommended for data that can be recreated
- Glacier Storage classes:
    - It provides low cost storage meant for archiving/backup
    - Pricing: storage + object retrieval cost
    - There are 3 classes of storage within Glacier:
        - Instant Retrieval:
            - Provides millisecond retrieval, great for data accessed once a quarter
            - Minimum storage duration is 90 days
        - Flexible Retrieval:
            - Providers 3 types of data retrieval:
                - Expedited: 1 - 5 minutes
                - Standard: 3 - 5 hours
                - Bulk: 5 - 12 hours (retrieval is free)
            - Minimum storage duration is 90 days
        - Deep Archive:
            - Providers 2 types of data retrieval:
                - Standard: up to 12 hours
                - Bulk: up to 48 hours
            - Minimum storage duration is 180 days
- Intelligent-Tiering:
    - Moves objects automatically between access tiers based on usage
    - There are no retrieval charges in S3 Intelligent-Tiering
    - There is a small monitoring and auto-tiering fee
    - Data us moved between the following tiers:
        - Frequent Access: default tier
        - Infrequent Access:  objects not accessed for 30 days
        - Archive Instant tier: objects not accessed fo 90 days
        - Archive Instant tier (optional): configurable from 90 days to 700+ days
        - Deep Archive Access tier (optional): configurable, same as before

## Moving Data between Storage Classes

- We can transition objects between storage classes according to the following diagram:

    ![Transition Between Storage Classes](images/lifecycle-transitions-v3.png)

- Moving objects can be automated using Lifecycle Rules
- Lifecycle Rules can be:
    - *Transition Actions*: configure objects to transition to another storage class. Example: move objects to Standard IA 60 after creation
    - *Expiration Actions*: configure objects to expire (be deleted) after some time. Examples of usages:
        - Delete files after 365 days
        - Delete old versions of a file if versioning is enabled
        - Delete incomplete Multi-Part uploads
- Rules can be specified to a bucket or to certain prefix
- Rules can be specified for tags as well

## Amazon S3 Analytics - Storage Class Analysis

- Helps us decide when to transition objects to the right storage class
- Offers recommendations for Standard and Standard IA, does not work with One-Zone IA or Glacier
- Produces a report a .csv report with after analyzing the content of a bucket, this report will be updated daily
- It can take up to 24 or 48 hours to get data analysis results

## S3 Encryption for Objects

- There are 4 methods of encrypting objects in S3:
    - **SSE-S3**: encrypts objects using a KMS key managed by AWS
    - **SSE-KMS**: we can use our own key stored in AWS Key Management Service. We can have additional permissions to the key and audit trail for the key usage
    - **SSE-C**: we can manage our own keys outside of AWS
    - **Client Side Encryption**: data is encrypted outside of AWS